{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax \n",
    "from jax import jit\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "from jax import lax\n",
    "\n",
    "'''for dataloading'''\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_Conv2D(key, in_channels, out_channels, kernel_shape):\n",
    "    key1, key2 = jax.random.split(key)\n",
    "    kernel = jax.random.normal(key1, (out_channels, in_channels) + kernel_shape)\n",
    "    bias = jax.random.normal(key2, (1, out_channels, 1, 1))\n",
    "\n",
    "    return dict(kernel=kernel, bias=bias)   \n",
    "\n",
    "def init_fc(key, input_dim, output_dim):\n",
    "    key1, key2 = jax.random.split(key)\n",
    "    weights = jax.random.normal(key1, (input_dim, output_dim))\n",
    "    bias = jax.random.normal(key2, (output_dim,))\n",
    "\n",
    "    return dict(weights=weights, bias=bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_Conv2D(params, x):\n",
    "    return lax.conv(x, params['kernel'], (1, 1), 'VALID') + params['bias']\n",
    "\n",
    "def forward_fc(params, x):\n",
    "    return jnp.dot(x, params['weights']) + params['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_mnist_convnet(key):\n",
    "    layers = []\n",
    "    key, *subkey = jax.random.split(key, num=6)\n",
    "    layers.append(init_Conv2D(subkey[0], 1, 1, (1, 1))) #28x28x1 -> 21x21x4\n",
    "    layers.append(init_Conv2D(subkey[1], 1, 1, (1, 1))) #21x21x4 -> 14x14x\n",
    "    layers.append(init_fc(subkey[2], 28*28, 200)) #14x14x8 -> 10\n",
    "    layers.append(init_fc(subkey[3], 200, 10)) #10 -> 10\n",
    "    return layers\n",
    "\n",
    "\n",
    "def forward_mnist_convnet(params, x):\n",
    "    x = jnp.reshape(x, (x.shape[0], -1))\n",
    "    x = forward_fc(params[2], x)\n",
    "    x = jax.nn.relu(x)\n",
    "    x = forward_fc(params[3], x)\n",
    "    x = jax.nn.log_softmax(x, axis=1)\n",
    "    return x\n",
    "\n",
    "def cross_entropy_loss(params, x, y):\n",
    "    pred = forward_mnist_convnet(params, x)\n",
    "    return -jnp.mean(jnp.sum(y * pred, axis=1))\n",
    "\n",
    "def mse_loss(params, x, y):\n",
    "    return jnp.mean((forward_mnist_convnet(params, x) - y) ** 2) \n",
    "\n",
    "@jit\n",
    "def update(params, x: jnp.ndarray, y: jnp.ndarray, lr: float):\n",
    "\n",
    "    grads = jax.grad(cross_entropy_loss)(params, x, y)    \n",
    "    return jax.tree_util.tree_map(\n",
    "       lambda p, g: p - lr * g, params, grads\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load minst\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='.',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='.',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 14:24:08.676623: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.0 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 16.510223388671875, Test accuracy: 0.7916000485420227\n",
      "Epoch: 1, Train loss: 6.261163711547852, Test accuracy: 0.8375000357627869\n",
      "Epoch: 2, Train loss: 4.716853618621826, Test accuracy: 0.8541000485420227\n",
      "Epoch: 3, Train loss: 3.888270378112793, Test accuracy: 0.86680006980896\n",
      "Epoch: 4, Train loss: 3.342078924179077, Test accuracy: 0.8747000694274902\n",
      "Epoch: 5, Train loss: 2.9581427574157715, Test accuracy: 0.8828000426292419\n",
      "Epoch: 6, Train loss: 2.662611246109009, Test accuracy: 0.8861000537872314\n",
      "Epoch: 7, Train loss: 2.4234538078308105, Test accuracy: 0.8891000151634216\n",
      "Epoch: 8, Train loss: 2.2271769046783447, Test accuracy: 0.893000066280365\n",
      "Epoch: 9, Train loss: 2.0588293075561523, Test accuracy: 0.8958000540733337\n",
      "Epoch: 10, Train loss: 1.9198358058929443, Test accuracy: 0.8997000455856323\n",
      "Epoch: 11, Train loss: 1.794801950454712, Test accuracy: 0.9003000259399414\n",
      "Epoch: 12, Train loss: 1.690253734588623, Test accuracy: 0.9027000665664673\n",
      "Epoch: 13, Train loss: 1.5948207378387451, Test accuracy: 0.9029000401496887\n",
      "Epoch: 14, Train loss: 1.5097863674163818, Test accuracy: 0.9066000580787659\n",
      "Epoch: 15, Train loss: 1.4327259063720703, Test accuracy: 0.9065000414848328\n",
      "Epoch: 16, Train loss: 1.363950252532959, Test accuracy: 0.9057000279426575\n",
      "Epoch: 17, Train loss: 1.3059686422348022, Test accuracy: 0.9103000164031982\n",
      "Epoch: 18, Train loss: 1.2466429471969604, Test accuracy: 0.9118000268936157\n",
      "Epoch: 19, Train loss: 1.1959891319274902, Test accuracy: 0.9131000638008118\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "params = init_mnist_convnet(key)\n",
    "lr = 0.01\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        x = x.reshape(-1, 1, 28, 28)\n",
    "        y = jax.nn.one_hot(y, 10)\n",
    "        loss = cross_entropy_loss(params, x, y)\n",
    "        params = update(params, x, y, lr)\n",
    "        loss_sum += loss\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in test_loader:\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        x = x.reshape(-1, 1, 28, 28)\n",
    "        y_pred = forward_mnist_convnet(params, x)\n",
    "        y_pred = jnp.argmax(y_pred, axis=1)\n",
    "        correct += (y_pred == y).sum()\n",
    "        total += y.shape[0]\n",
    "    print(f'Epoch: {epoch}, Train loss: {loss_sum / i}, Test accuracy: {correct / total}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
